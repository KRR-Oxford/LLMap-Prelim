{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the maximum memory located to JVM [8g]:\n",
      "8g maximum memory allocated to JVM.\n",
      "JVM started successfully.\n"
     ]
    }
   ],
   "source": [
    "from deeponto.onto import Ontology\n",
    "from deeponto.align.bertmap import BERTMapPipeline\n",
    "from deeponto.align.evaluation import AlignmentEvaluator\n",
    "from deeponto.utils import FileUtils\n",
    "from deeponto.align.mapping import EntityMapping, ReferenceMapping\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cands = FileUtils.read_table(\"data/ncit2doid/test_cands.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the default configuration at /home/yuan/anaconda3/envs/deeponto/lib/python3.8/site-packages/deeponto/align/bertmap/default_config.yaml.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Time: 00:03:24] - [PID: 2304892] - [Model: bertmap] \n",
      "Load the following configurations:\n",
      "{\n",
      "    \"model\": \"bertmap\",\n",
      "    \"output_path\": \"/home/yuan/projects/LLMap/experiments/ncit2doid.us\",\n",
      "    \"annotation_property_iris\": [\n",
      "        \"http://www.w3.org/2000/01/rdf-schema#label\",\n",
      "        \"http://www.geneontology.org/formats/oboInOwl#hasSynonym\",\n",
      "        \"http://www.geneontology.org/formats/oboInOwl#hasExactSynonym\",\n",
      "        \"http://www.w3.org/2004/02/skos/core#exactMatch\",\n",
      "        \"http://www.ebi.ac.uk/efo/alternative_term\",\n",
      "        \"http://www.orpha.net/ORDO/Orphanet_#symbol\",\n",
      "        \"http://purl.org/sig/ont/fma/synonym\",\n",
      "        \"http://www.w3.org/2004/02/skos/core#prefLabel\",\n",
      "        \"http://www.w3.org/2004/02/skos/core#altLabel\",\n",
      "        \"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P108\",\n",
      "        \"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P90\"\n",
      "    ],\n",
      "    \"known_mappings\": null,\n",
      "    \"auxiliary_ontos\": [],\n",
      "    \"bert\": {\n",
      "        \"pretrained_path\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
      "        \"max_length_for_input\": 128,\n",
      "        \"num_epochs_for_training\": 3.0,\n",
      "        \"batch_size_for_training\": 32,\n",
      "        \"batch_size_for_prediction\": 128,\n",
      "        \"resume_training\": null\n",
      "    },\n",
      "    \"global_matching\": {\n",
      "        \"enabled\": false,\n",
      "        \"num_raw_candidates\": 200,\n",
      "        \"num_best_predictions\": 10,\n",
      "        \"mapping_extension_threshold\": 0.9,\n",
      "        \"mapping_filtered_threshold\": 0.9995\n",
      "    }\n",
      "}\n",
      "[Time: 00:00:00] - [PID: 2304892] - [Model: bertmap] \n",
      "Load the following configurations:\n",
      "{\n",
      "    \"model\": \"bertmap\",\n",
      "    \"output_path\": \"/home/yuan/projects/LLMap/experiments/ncit2doid.us\",\n",
      "    \"annotation_property_iris\": [\n",
      "        \"http://www.w3.org/2000/01/rdf-schema#label\",\n",
      "        \"http://www.geneontology.org/formats/oboInOwl#hasSynonym\",\n",
      "        \"http://www.geneontology.org/formats/oboInOwl#hasExactSynonym\",\n",
      "        \"http://www.w3.org/2004/02/skos/core#exactMatch\",\n",
      "        \"http://www.ebi.ac.uk/efo/alternative_term\",\n",
      "        \"http://www.orpha.net/ORDO/Orphanet_#symbol\",\n",
      "        \"http://purl.org/sig/ont/fma/synonym\",\n",
      "        \"http://www.w3.org/2004/02/skos/core#prefLabel\",\n",
      "        \"http://www.w3.org/2004/02/skos/core#altLabel\",\n",
      "        \"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P108\",\n",
      "        \"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P90\"\n",
      "    ],\n",
      "    \"known_mappings\": null,\n",
      "    \"auxiliary_ontos\": [],\n",
      "    \"bert\": {\n",
      "        \"pretrained_path\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
      "        \"max_length_for_input\": 128,\n",
      "        \"num_epochs_for_training\": 3.0,\n",
      "        \"batch_size_for_training\": 32,\n",
      "        \"batch_size_for_prediction\": 128,\n",
      "        \"resume_training\": null\n",
      "    },\n",
      "    \"global_matching\": {\n",
      "        \"enabled\": false,\n",
      "        \"num_raw_candidates\": 200,\n",
      "        \"num_best_predictions\": 10,\n",
      "        \"mapping_extension_threshold\": 0.9,\n",
      "        \"mapping_filtered_threshold\": 0.9995\n",
      "    }\n",
      "}\n",
      "INFO:bertmap:Load the following configurations:\n",
      "{\n",
      "    \"model\": \"bertmap\",\n",
      "    \"output_path\": \"/home/yuan/projects/LLMap/experiments/ncit2doid.us\",\n",
      "    \"annotation_property_iris\": [\n",
      "        \"http://www.w3.org/2000/01/rdf-schema#label\",\n",
      "        \"http://www.geneontology.org/formats/oboInOwl#hasSynonym\",\n",
      "        \"http://www.geneontology.org/formats/oboInOwl#hasExactSynonym\",\n",
      "        \"http://www.w3.org/2004/02/skos/core#exactMatch\",\n",
      "        \"http://www.ebi.ac.uk/efo/alternative_term\",\n",
      "        \"http://www.orpha.net/ORDO/Orphanet_#symbol\",\n",
      "        \"http://purl.org/sig/ont/fma/synonym\",\n",
      "        \"http://www.w3.org/2004/02/skos/core#prefLabel\",\n",
      "        \"http://www.w3.org/2004/02/skos/core#altLabel\",\n",
      "        \"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P108\",\n",
      "        \"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P90\"\n",
      "    ],\n",
      "    \"known_mappings\": null,\n",
      "    \"auxiliary_ontos\": [],\n",
      "    \"bert\": {\n",
      "        \"pretrained_path\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
      "        \"max_length_for_input\": 128,\n",
      "        \"num_epochs_for_training\": 3.0,\n",
      "        \"batch_size_for_training\": 32,\n",
      "        \"batch_size_for_prediction\": 128,\n",
      "        \"resume_training\": null\n",
      "    },\n",
      "    \"global_matching\": {\n",
      "        \"enabled\": false,\n",
      "        \"num_raw_candidates\": 200,\n",
      "        \"num_best_predictions\": 10,\n",
      "        \"mapping_extension_threshold\": 0.9,\n",
      "        \"mapping_filtered_threshold\": 0.9995\n",
      "    }\n",
      "}\n",
      "[Time: 00:03:24] - [PID: 2304892] - [Model: bertmap] \n",
      "Save the configuration file at /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/config.yaml.\n",
      "[Time: 00:00:00] - [PID: 2304892] - [Model: bertmap] \n",
      "Save the configuration file at /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/config.yaml.\n",
      "INFO:bertmap:Save the configuration file at /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/config.yaml.\n",
      "[Time: 00:03:27] - [PID: 2304892] - [Model: bertmap] \n",
      "Load existing text semantics corpora from /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/data/text-semantics.corpora.json.\n",
      "[Time: 00:00:02] - [PID: 2304892] - [Model: bertmap] \n",
      "Load existing text semantics corpora from /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/data/text-semantics.corpora.json.\n",
      "INFO:bertmap:Load existing text semantics corpora from /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/data/text-semantics.corpora.json.\n",
      "[Time: 00:03:29] - [PID: 2304892] - [Model: bertmap] \n",
      "Load existing fine-tuning data from /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/data/fine-tune.data.json.\n",
      "[Time: 00:00:04] - [PID: 2304892] - [Model: bertmap] \n",
      "Load existing fine-tuning data from /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/data/fine-tune.data.json.\n",
      "INFO:bertmap:Load existing fine-tuning data from /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/data/fine-tune.data.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a BERT model from: /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/bert/checkpoint-45300.\n",
      "The BERT model is set to eval mode for making predictions.\n",
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: Quadro RTX 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Time: 00:03:46] - [PID: 2304892] - [Model: bertmap] \n",
      "Fine-tuning finished, found best checkpoint at /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/bert/checkpoint-45300.\n",
      "[Time: 00:00:21] - [PID: 2304892] - [Model: bertmap] \n",
      "Fine-tuning finished, found best checkpoint at /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/bert/checkpoint-45300.\n",
      "INFO:bertmap:Fine-tuning finished, found best checkpoint at /home/yuan/projects/LLMap/experiments/ncit2doid.us/bertmap/bert/checkpoint-45300.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".enlighten-bold {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".enlighten-underline {\n",
       "  text-decoration: underline;\n",
       "}\n",
       ".enlighten-fg-bright-white {\n",
       "  color: #ffffff;\n",
       "}\n",
       ".enlighten-bg-lightslategray {\n",
       "  background-color: #778899;\n",
       "}\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre><span class=\"enlighten-bold enlighten-underline enlighten-fg-bright-white enlighten-bg-lightslategray\">Global Matching                                 Stage: Skipped                                 00:02</span></pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Time: 00:03:46] - [PID: 2304892] - [Model: bertmap] \n",
      "Build inverted annotation index for candidate selection.\n",
      "[Time: 00:00:21] - [PID: 2304892] - [Model: bertmap] \n",
      "Build inverted annotation index for candidate selection.\n",
      "INFO:bertmap:Build inverted annotation index for candidate selection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 0.9\n"
     ]
    }
   ],
   "source": [
    "config = BERTMapPipeline.load_bertmap_config()\n",
    "config.global_matching.enabled = False\n",
    "config.output_path = \"experiments/ncit2doid.us/\"\n",
    "src_onto_path = \"data/ncit2doid/ncit.owl\"\n",
    "tgt_onto_path = \"data/ncit2doid/doid.owl\"\n",
    "src_onto = Ontology(src_onto_path)\n",
    "tgt_onto = Ontology(tgt_onto_path)\n",
    "\n",
    "bertmap = BERTMapPipeline(src_onto, tgt_onto, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmap_results = []\n",
    "bertmaplt_results = []\n",
    "for i, dp in test_cands.iterrows():\n",
    "    \n",
    "    bertmap_mappings = []\n",
    "    bertmaplt_mappings = []\n",
    "    \n",
    "    src_class_iri = dp[\"SrcEntity\"]\n",
    "    tgt_class_iri = dp[\"TgtEntity\"]\n",
    "    tgt_cands = eval(dp[\"TgtCandidates\"])\n",
    "    \n",
    "    # retrieve class annotations\n",
    "    src_class_labels = bertmap.src_annotation_index[src_class_iri]\n",
    "    \n",
    "    for tgt_cand_iri in tgt_cands:\n",
    "        tgt_cand_labels = bertmap.tgt_annotation_index[tgt_cand_iri]\n",
    "        # the bertmap score\n",
    "        bertmap_score = bertmap.mapping_predictor.bert_mapping_score(\n",
    "            src_class_labels, tgt_cand_labels\n",
    "        )\n",
    "        bertmap_mappings.append(EntityMapping(src_class_iri, tgt_cand_iri, \"=\", bertmap_score))\n",
    "        # the bertmaplt score\n",
    "        bertmaplt_score = bertmap.mapping_predictor.edit_similarity_mapping_score(\n",
    "            src_class_labels, tgt_cand_labels\n",
    "        )\n",
    "        bertmaplt_mappings.append(EntityMapping(src_class_iri, tgt_cand_iri, \"=\", bertmaplt_score))\n",
    "        \n",
    "    bertmap_results.append(EntityMapping.sort_entity_mappings_by_score(bertmap_mappings))\n",
    "    bertmaplt_results.append(EntityMapping.sort_entity_mappings_by_score(bertmaplt_mappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def mean_reciprocal_rank(prediction_and_candidates):\n",
    "    r\"\"\"Compute $MRR$ for a list of `(prediction_mapping, candidate_mappings)` pair.\n",
    "\n",
    "    $$MRR = \\sum_i^N rank_i^{-1} / N$$\n",
    "    \"\"\"\n",
    "    sum_inverted_ranks = 0\n",
    "    for pred, cands in prediction_and_candidates:\n",
    "        ordered_candidates = [c.to_tuple() for c in EntityMapping.sort_entity_mappings_by_score(cands)]\n",
    "        if pred.to_tuple() in ordered_candidates:\n",
    "            rank = ordered_candidates.index(pred.to_tuple()) + 1\n",
    "        else:\n",
    "            rank = math.inf\n",
    "        sum_inverted_ranks += 1 / rank\n",
    "    return sum_inverted_ranks / len(prediction_and_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bertmap\n",
    "results_dict = dict()\n",
    "for i, mappings in enumerate(bertmap_results):\n",
    "    results_dict[test_cands.iloc[i][\"SrcEntity\"], test_cands.iloc[i][\"TgtEntity\"]] = mappings\n",
    "FileUtils.save_file(results_dict, \"bertmap_ncit2doid_results.pkl\")\n",
    "# manually move results to the result folder\n",
    "ranked_results = FileUtils.load_file(\"bertmap_ncit2doid_results.pkl\")\n",
    "# the first 50 mappings are the matched mappings\n",
    "refs = ReferenceMapping.read_table_mappings(\"data/ncit2doid/refs/test_refs.tsv\")[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P': 0.759, 'R': 0.44, 'F1': 0.557}\n",
      "22 46 68\n",
      "0.9337777777777779\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.9995\n",
    "# Precision, Recall, F1\n",
    "preds = []\n",
    "for (src, tgt), mappings in ranked_results.items():\n",
    "    # for t, answer, score in tgt_cands:\n",
    "    for m in mappings:\n",
    "        if m.score >= threshold:\n",
    "            preds.append(m)\n",
    "print(AlignmentEvaluator.f1(preds, refs, []))\n",
    "\n",
    "# Accuracy\n",
    "yes_correct = 0\n",
    "no_correct = 0\n",
    "for (src, tgt), mappings in ranked_results.items():\n",
    "    # print(tgt_cands[0])\n",
    "    for m in mappings:\n",
    "        score = m.score\n",
    "        if tgt == m.tail and score >= threshold:\n",
    "            yes_correct += 1\n",
    "    \n",
    "    if tgt == \"UnMatched\" and mappings[0].score< threshold:\n",
    "        no_correct += 1\n",
    "print(yes_correct, no_correct, yes_correct + no_correct)\n",
    "\n",
    "# MRR\n",
    "formatted_results = []\n",
    "for (src, tgt), mappings in ranked_results.items():\n",
    "    ref_mapping = EntityMapping(src, tgt, \"=\", 1.0)\n",
    "    formatted_results.append((ref_mapping, mappings))\n",
    "# again, only the first 50 has a match\n",
    "print(mean_reciprocal_rank(formatted_results[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bertmaplt\n",
    "results_dict = dict()\n",
    "for i, mappings in enumerate(bertmaplt_results):\n",
    "    results_dict[test_cands.iloc[i][\"SrcEntity\"], test_cands.iloc[i][\"TgtEntity\"]] = mappings\n",
    "FileUtils.save_file(results_dict, \"bertmaplt_ncit2doid_results.pkl\")\n",
    "# manually move results to the result folder\n",
    "ranked_results = FileUtils.load_file(\"bertmaplt_ncit2doid_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P': 0.196, 'R': 0.18, 'F1': 0.187}\n",
      "9 46 55\n",
      "0.5160657125437978\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.9\n",
    "# Precision, Recall, F1\n",
    "preds = []\n",
    "for (src, tgt), mappings in ranked_results.items():\n",
    "    # for t, answer, score in tgt_cands:\n",
    "    for m in mappings:\n",
    "        if m.score >= threshold:\n",
    "            preds.append(m)\n",
    "print(AlignmentEvaluator.f1(preds, refs, []))\n",
    "\n",
    "# Accuracy\n",
    "yes_correct = 0\n",
    "no_correct = 0\n",
    "for (src, tgt), mappings in ranked_results.items():\n",
    "    # print(tgt_cands[0])\n",
    "    for m in mappings:\n",
    "        score = m.score\n",
    "        if tgt == m.tail and score >= threshold:\n",
    "            yes_correct += 1\n",
    "    \n",
    "    if tgt == \"UnMatched\" and mappings[0].score< threshold:\n",
    "        no_correct += 1\n",
    "print(yes_correct, no_correct, yes_correct + no_correct)\n",
    "\n",
    "# MRR\n",
    "formatted_results = []\n",
    "for (src, tgt), mappings in ranked_results.items():\n",
    "    ref_mapping = EntityMapping(src, tgt, \"=\", 1.0)\n",
    "    formatted_results.append((ref_mapping, mappings))\n",
    "# again, only the first 50 has a match\n",
    "print(mean_reciprocal_rank(formatted_results[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeponto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
